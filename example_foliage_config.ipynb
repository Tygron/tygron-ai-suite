{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82822eff-c6db-4cf8-b47d-2c93e5b577ac",
   "metadata": {},
   "source": [
    "<h1>Training a Convolutional Neural Network for Foliage</h1>\n",
    "<p>This example notebook is a more comprehensive example with a configuration for training a convolutional neural network for recognizing foliage. If you would like to learn step by step what is done, please refer to the  'example_config.ipynb' notebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95a3e71d-3455-405b-974f-f0d980e4b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_training import Configuration, ImageDataset\n",
    "from inference_training import initCudaEnvironment, createTransforms\n",
    "from inference_training import drawImageAndFeatureMasks\n",
    "from inference_training import exportOnnxModel, writeONNXMeta, loadONNX\n",
    "from inference_training import trainModel, saveModel, loadModel\n",
    "from inference_training import createModelInstance, testInference\n",
    "from inference_training import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "271a4c11-5b60-4f45-a504-8be8e706018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initCudaEnvironment(numCudaDevices=1,\n",
    "                    visibleCudaDevices=\"0\",\n",
    "                    clearCudaDeviceCount=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21550852-e9f6-4f2d-98e8-e2d46365b967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The datasets directory does not exist: /path/to/train_dataset\n",
      "Please adjust the configured dataset directory in the configuration file!\n",
      "The datasets directory does not exist: /path/to/test_dataset\n",
      "Please adjust the configured dataset directory in the configuration file!\n",
      "No files were found in the Training dataset\n",
      "No files were found in the Test dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "config = Configuration()\n",
    "print(\"Device: \" + str(config.device))\n",
    "\n",
    "trainDirectory = \"/path/to/train_dataset/\"\n",
    "testDirectory = \"/path/to/test_dataset/\"\n",
    "\n",
    "config.setDatasetPaths(trainPath=trainDirectory, testPath=testDirectory)\n",
    "config.setFilePrefix(\"foliage_\")\n",
    "config.setModelName(\"foliage\")\n",
    "config.setInputSizes(inputWidth=250, inputHeight=250)\n",
    "config.setInputCellSize(cellSizeM=0.25, minCellSizeM=0.1, maxCellSizeM=0.5)\n",
    "config.setAutoLimitLabel(True)\n",
    "\n",
    "logger.info(\"Version: \" + str(config.version))\n",
    "\n",
    "config.setModelInfo(channels=3, numClasses=8+1,  # (1 + background)\n",
    "                    bboxOverlap=True, bboxPerImage=250, reuseModel=False)\n",
    "config.setEpochs(0)\n",
    "\n",
    "description = \"Inference model to detect deciduous trees, pine trees, \"\\\n",
    "    \"heather, hedges, plants, reed, shrubbery, flowbeds. \" \\\n",
    "    \"Additionally regions of decidious trees without leaves can be detected.\"\n",
    "config.setOnnxInfo(producer=\"Tygron\", description=description)\n",
    "\n",
    "config.addLegendEntry(\"Background\", 0, \"#00000000\")\n",
    "config.addLegendEntry(\"Deciduous Tree\", 1, \"#00ffbf\")\n",
    "config.addLegendEntry(\"Pine Tree\", 2, \"#12d900\")\n",
    "config.addLegendEntry(\"Heather\", 3, \"#f3a6b2\")\n",
    "config.addLegendEntry(\"Hedge\", 4, \"#8d5a99\")\n",
    "config.addLegendEntry(\"Shrubbery\", 5, \"#e80004\")\n",
    "config.addLegendEntry(\"Reed\", 6, \"#f8ff20\")\n",
    "config.addLegendEntry(\"Flowerbed\", 7, \"#b7484b\")\n",
    "config.addLegendEntry(\"Deciduous Tree (Leafless)\", 8, \"#e6994d\")\n",
    "\n",
    "config.setOnnxMetaData(scoreThreshold=0.2,\n",
    "                       maskThreshold=0.3,\n",
    "                       strideFraction=0.5)\n",
    "\n",
    "config.setTensorInfo(tensorName='input_A:RGB_normalized', batchAmount=1)\n",
    "trainingDataset = ImageDataset(config, True, createTransforms(True))\n",
    "testDataset = ImageDataset(config, False, createTransforms(False))\n",
    "\n",
    "logger.info(\"Train Image count: \"+str(trainingDataset.__len__()))\n",
    "logger.info(\"Test Image count: \"+str(testDataset.__len__()))\n",
    "\n",
    "trainingDataset.validate()\n",
    "testDataset.validate()\n",
    "\n",
    "logger.info(\"Pytorch model name \" + config.getPytorchModelFileName())\n",
    "logger.info(\"Onnx file name \" + config.getOnnxFileName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a09aea7a-9a3a-4ec4-a161-55173a86cdfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m imageNumber \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(trainingDataset\u001b[38;5;241m.\u001b[39mgetLabels(imageNumber))\n\u001b[1;32m      3\u001b[0m drawImageAndFeatureMasks(config, trainingDataset, imageNumber)\n",
      "File \u001b[0;32m~/git/tygron-ai/tygron-ai-suite/inference_training.py:283\u001b[0m, in \u001b[0;36mImageDataset.getLabels\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetLabels\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 283\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    284\u001b[0m     result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "imageNumber = 5\n",
    "print(trainingDataset.getLabels(imageNumber))\n",
    "drawImageAndFeatureMasks(config, trainingDataset, imageNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00f639e7-aa3c-4001-82b5-fec4fe86f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files were found in the Training dataset\n",
      "Training dataset is invalid, please inspect the logs.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m trainModel(config, trainingDataset, testDataset)\n\u001b[0;32m----> 2\u001b[0m saveModel(config, model, path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgetPytorchModelFileName())\n",
      "File \u001b[0;32m~/git/tygron-ai/tygron-ai-suite/inference_training.py:804\u001b[0m, in \u001b[0;36msaveModel\u001b[0;34m(config, model, path)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m     path \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mgetPytorchModelFileName()\n\u001b[0;32m--> 804\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "model = trainModel(config, trainingDataset, testDataset)\n",
    "saveModel(config, model, path=config.getPytorchModelFileName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042aede8-7ac6-45be-a82d-31c1852f1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "testPrediction = testInference(config, model=model,\n",
    "                               dataset=testDataset, imageNumber=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ca3f6-abbf-408b-afb3-91084272533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportOnnxModel(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701edd17-f779-4c1a-9c9e-4f50dbbbabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeONNXMeta(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe11d4-d9b7-4ed1-9473-1379cb506e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = loadONNX(config)\n",
    "print(f\"metadata_props={onnx_model.metadata_props}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
